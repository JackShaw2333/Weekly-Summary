# Week #1
## 简介
1. 吴恩达的课程：主要关于深度卷积神经网络的实例探究。
2. CS231N主要关于一些简单的算法及其具体代码实现细节。
3. Numpy&Pandas入门学习。

## 主要内容
### [网易云课堂 吴恩达 卷积神经网络](https://mooc.study.163.com/learn/2001281004?tid=2001392030#/learn/content)
#### 2.5 网络中的网络以及1x1卷积
![TIM截图20180914092814](screenshots/TIM%E6%88%AA%E5%9B%BE20180914092814.png)
1x1卷积也称为`Network in network`，因为每一次卷积相当于一个全连接层，对输入层的1x1x信道数切片进行运算。
它给神经网络添加了一个非线性函数，并能够在保持输入层长宽的基础上改变信道的数量。
输出结果的信道数等于使用的卷积核的数量。
1x1卷积在`Inception网络`中得到应用

#### 2.6 谷歌Inception网络简介
Inception网络可以代替人工确定卷积层中的卷积核类型，确定是否需要创建卷积层或池化层。
![Inception网络](screenshots/TIM%E6%88%AA%E5%9B%BE20180914094011.png)
以上图为例，输入层为`28x28x192`。
1. 先使用64个1x1的卷积核，输出大小为28x28x64。
2. 再使用128个3x3的`Same`卷积核，输出大小为28x28x128，将这一层叠到上一个输出层上。
3. 然后使用32个5x5的`Same`卷积核，输出大小为28x28x32，将这一层叠到之前的输出层上。
4. 最后再进行最大值池化，`Same padding`，步长为1，输出大小为28x28x32，继续叠到之前的输出层上去。

这样就粗略得到了一个`Inception模块`，对于这个例子而言，输入为28x28x192，输出为28x28x256。
以上就是`Inception模块`的核心内容。
基本思想是：Inception网络不需要人为决定需要哪种卷积核或是否需要池化，而是由网络自行决定。我们可以对网络使用这些参数然后把输出连接起来。让网络自己学习它需要什么参数，采用哪些卷积核组合。


然而不难发现，Inception网络存在计算成本的问题。
以使用32个5x5的卷积核进行`Same`卷积，输入层为28x28x192为例。
32个5x5的卷积核，每个卷积核大小为5x5x192，而输出为28x28x32，即要计算28x28x32个数字，而对于其中的每个数字，都要进行5x5x192次运算。所以**乘法运算的总次数为每个输出值所需的乘法次数乘输出的值个数**，这里的结果大约为**1.2亿**次乘法运算。


然而，当我们应用`1x1卷积`后，计算量可降低为原先的十分之一。
![TIM截图20180914150926](screenshots/TIM%E6%88%AA%E5%9B%BE20180914150926.png)
然后对这个较小层，运用5x5的卷积核，同样输出层大小为28x28x32。
![TIM截图20180914151108](TIM%E6%88%AA%E5%9B%BE20180914151108.png)
通过这样1x1卷积构建`瓶颈层`可降低运算量，先缩小网络表示，再增大它们。
这样计算成本为：
1. 构建瓶颈层，计算量为28x28x16x192，约等于240万
2. 对于第二个卷积层，计算量为28x28x32x5x5x16，约等于1000万。

所以总乘法次数为1240万（加法次数与乘法次数近似相同）







#### 2.7 Inception网络
Inception模块主要使用之前层的激活或输出作为输入。
还以28x28x192的输入层为例
![TIM截图20180914191812](screenshots/TIM%E6%88%AA%E5%9B%BE20180914151108.png)









1. 16个1x1卷积核卷积，32个5x5卷积核`Same`卷积，输出大小为28x28x32
2. 16个1x1卷积核卷积，128个3x3卷积核`Same`卷积，输出大小为28x28x128
3. 64个1x1卷积核卷积。
4. 3x3，步长1的最大值池化层`Same`池化，然后再用32个1x1的卷积核压缩信道数量。输出为28x28x32。
5. 最后将所有信道连接在一起。完成了一个Inception模块的构建。




















![TIM截图20180914192852](screenshots/TIM%E6%88%AA%E5%9B%BE20180914191812.png)
将许多重复的Inception模块连接在一起，就构建了一个Inception网络。有的模块与模块之间存在池化层条件维度大小。




















![TIM截图20180914194142](screenshots/TIM%E6%88%AA%E5%9B%BE20180914192852.png)
![TIM截图20180914200147](screenshots/TIM%E6%88%AA%E5%9B%BE20180914194142.png)
其中有一个细节要注意，Inception网络同时还有几条分支，这几条分支是用`Softmax`进行预测的全连接层。它们确保了即便是隐藏单元和中间层，也参与了特征计算，得出了对图片的分类。对整个Inception网络起到了调整的作用，也防止了网络发生过拟合。

论文：[[Szegedy et al.,2014, Going Deeper with Convolutions]](https://arxiv.org/abs/1409.4842)







#### 2.8 使用开源的实现方案
搭建计算机视觉网络比较好的方式是使用自己感兴趣的框架，到Github上下载开源的实现。这样做可以节省许多从头开始训练网络的时间。我们就可以利用这些预训练的网络进行迁移学习，运用到我们的网络上去。






#### 2.9 迁移学习
做计算机视觉项目时，可以下载开源项目，利用他人已经训练好的网络结构的权重，将之作为预训练，然后转换到自己感兴趣的任务上。

例如，我们要搭建一个识别猫的3分类神经网络。我们可以下载别人预训练好的网络模型。如我们下载了`ImageNet数据集`的网络，这个网络用Softmax输出1000种类别。我们可以删去它的Softmax层，用我们自己的3分类的Softmax层替代。
若训练数据少，可冻结之前的隐层，只训练最后的Softmax层的参数。这样，即便训练数据不大，我们仍能得到较好的效果。
许多框架都支持这种`冻结参数`的操作。

还有一个能加快计算速度的小技巧。由于前面的层都冻结了，相当于一个固定的函数。

![TIM截图20180914200903](screenshots/TIM%E6%88%AA%E5%9B%BE20180914200147.png)
然后我们将输入图片直接映射到Softmax层的前一层的激活函数中去。如果我们这样先计算这一层的特征或激活值，然后把它们存到硬盘，实际上就是用一个固定的函数，取任意图像，计算它的特征向量，这样就训练了一个很浅的Softmax模型，然后将参数权重存到硬盘。这样每次遍历就不需要再训练这一层的激活值了。
![TIM截图20180914203659](screenshots/TIM%E6%88%AA%E5%9B%BE20180914200903.png)
如果数据集较多，我们可以少冻结一些层。冻结前面的层，训练后面的层。










我们可以将后面几层原有的参数看作随机初始化然后进行梯度下降。
或者直接去掉后面几层换成自己隐藏单元。

有个规律：数据越多，需要冻结的层数就越少。
如果有大量数据，不要仅仅训练一个Softmax层，最好训练一个中等深度的网络。包含最终要用的网络的后面几层。
如果数据量足够大，可以完全自己训练。

#### 2.10 数据扩充
计算机视觉的一个特点：数据越多结果可能越好。
计算机视觉的一个问题：数据不够

常见的数据扩充方法：

垂直镜像对称












![TIM截图20180914203837](screenshots/TIM%E6%88%AA%E5%9B%BE20180914203659.png)
随机修剪（不完美）






旋转、局部扭曲（不推荐）


![TIM截图20180914204330](screenshots/TIM%E6%88%AA%E5%9B%BE20180914203837.png)
色彩转换，修改RGB值（可使用PCA颜色增强算法）
PCA增强算法将会使图片的RGB值趋向平均。如图片呈现紫色，则主要含红色与蓝色，而绿色很少，PCA算法便会将红色与蓝色的值减少很多，适当增加绿色值以使总体的颜色保持一致。
![TIM截图20180914205653](screenshots/TIM%E6%88%AA%E5%9B%BE20180914204330.png)










如果数据过大，那么数据的扩充和训练过程可并行执行。
使用CPU线程不停地从硬盘读取图片流，同时实现对图片的扭曲（垂直反转/随机裁剪/色彩转换）。每一种照片得到对应的一种扭曲形式。与此同时CPU线程不断加载数据，然后实现任意扭曲，从而构成批数据或最小批数据。这些数据持续地传给其他线程或其他进程然后训练。这些可以在CPU或者GPU上运行。

常用的数据增强方法是使用一个线程或多线程，这些可以用来加载数据和实现扭曲操作，然后传给其他线程或进程，以上这些都可以并行实现。

与构建神经网络相同，数据增强也有许多超参数需要设置。推荐的方法是使用别人的开源实现。


#### 2.11 计算机视觉现状







![TIM截图20180914191812](screenshots/TIM%E6%88%AA%E5%9B%BE20180914205653.png)
计算机视觉的数据相比其他领域偏少。
目标检测的数据相比物体识别更少。
当数据集很大时，人们倾向于使用简单的算法和更少的手工工程，因此人们不需要对这个问题精心设计。相反，我们可以用一个巨大的神经网络或一个简单的框架。
然而当没有那么多数据时，人们更多从事的是手工工程。当没有足够数据时，手工工程是获得良好表现的最佳方法。

算法一般有两种知识来源：
1. 被标记的数据。
2. 手工工程

人们精心建立一个系统，精心设计特性、网络特征结构或者是系统的其他组件。当没有太多的标记数据时，就需要更多的考虑手工工程。因此历史上，计算机视觉领域更加依赖手工工程。

在benchmarks训练出更好的结果就可以发表论文；对于计算机视觉比赛，模型表现提高1%、2%都很重要。针对这方面有一些技巧可以使用。

1. 集成。想好了自己的神经网络后，独立地再训练几个网络，然后将输出值平均。（不要平均它们的权重），这能够使表现提高1%、2%或更高。然而计算量成倍增加，因此不使用在为客户服务的系统上。
2. Multi-crop. 将数据增强应用到**测试集**中。如`10-crop`算法，
![TIM截图20180914211245](screenshots/TIM%E6%88%AA%E5%9B%BE20180914211122.png)
![TIM截图20180914211411](TIM%E6%88%AA%E5%9B%BE20180914211411.png)右上，左下，右下四个角进行crop，就得到4张图片
![TIM截图20180914211245](screenshots/TIM%E6%88%AA%E5%9B%BE20180914211411.png)
![TIM截图20180914211506](screenshots/TIM%E6%88%AA%E5%9B%BE20180914211506.png)
一共剪切出10张图片。然后用分类器运行这10张图片再将输出平均。

总之以上的方法使得计算量增大，耗时增长。研究论文和比赛时可以使用这些技巧，但是在开发部署客户的系统上，不推荐使用这些方法。

下图是开发模型的一些建议
![TIM截图20180914211942](screenshots/TIM%E6%88%AA%E5%9B%BE20180914211942.png)






### 斯坦福CS231N课程

#### 2.1 图像分类 - 数据驱动方法
**图片分类**是计算机视觉的一个核心问题。
对于机器来说，识别图片是一个非常难的问题，计算机看到图片时，没有物体的整体概念，它看到的是一堆数字，每个像素由三个数字表示，给出像素红绿蓝三个值，这些数字构成了一个大阵列。
这个问题被称为**语义鸿沟**，对于图片的概念是我们赋予图像的一个语义标签，这些语义概念和计算机实际看到的像素值之间有着巨大差距。
在视角、照明、变形、遮挡、背景混乱、类内差异的情况下，算法仍需具有鲁棒性。

为了识别图片，科学家们开始选择计算图像边缘，然后把边角各种形状分类，写一些规则进行分类。但迁移能力很差。

于是数据驱动的方法兴起了。

于是我们的API改变了，不是一个函数，接收一个图片输入，输出一个类别，而是有两个函数，一个是训练函数，一个是预测函数。

`K近邻算法`可以算是最简单的分类器。训练过程中我们只是单纯地记录数据，在预测时，我们用在数据集里寻找与新图片最相似的，然后基于此来给出一个标签。

以`CIFAR10`数据集为例，它给出10个类别，50000个训练图片，10000个测试图片。
在`K近邻算法`中，比较函数很重要，有一种方法是计算`L1距离`又称曼哈顿距离。
![TIM截图20180916143842](screenshots/TIM%E6%88%AA%E5%9B%BE20180916143842.png)
我们用测试图片的像素值减去训练图片的像素值再取绝对值，然后将所有像素加和。

对于一个有N个数据的模型，训练的时间复杂度是O(1)，训练的时间复杂度是O(N)，这个过程其实很落后，因为实际应用时，我们希望预测能快一点。
![TIM截图20180916144331](screenshots/TIM%E6%88%AA%E5%9B%BE20180916144331.png)
如果仅仅使`K=1`会出现过拟合的情况，所以我们应当适当放大K的值来避免过拟合，找到最近的K个点，然后投票来判断新数据的类别。

#### 2.2 图像分类 - K最近邻算法
比较图片之间的差异有两种算法可供选择。
如图所示。
![TIM截图20180916144607](screenshots/TIM%E6%88%AA%E5%9B%BE20180916144607.png)
L1(Manhattan)距离
![$$d_1(I_1,I_2)=\sum_p|I_1^p-I_2^p|$$](http://latex.codecogs.com/gif.latex?\\$$d_1(I_1,I_2)=\sum_p|I_1^p-I_2^p|$$)​

L2(Euclidean)距离
![$$d_1(I_1,I_2)=\sqrt{\sum_p(I_1^p-I_2^p)^2}$$](http://latex.codecogs.com/gif.latex?\\$$d_1(I_1,I_2)=\sqrt{\sum_p(I_1^p-I_2^p)^2}$$)​

在L1的图中，正方形边上各点与原点的L1距离是相同的。所以是否采用L1距离计算方法取决于坐标系统。如果转动坐标轴，L1的距离会发生变化而L2则不受影响。如果向量中的某些值有特殊意义，使用L1距离可能是更好的选择。

通过选取不同的距离计算方法，我们可以扩展数据的类型，譬如对文本进行分类等等。

关于如何选择超参数的问题？
尝试各种超参数组合，寻找最适合特定问题的组合。

选择超参数的标准？
1. 不能选择在数据集上表现最好的参数，因为它们极有可能导致过拟合。我们关心的不是数据是否在训练集上表现优秀，而是是否在训练集以外的未知数据上表现得更好。
![TIM截图20180916145356](screenshots/TIM%E6%88%AA%E5%9B%BE20180916145356.png)
2. 不能仅仅将数据划分为训练集和测试集，然后选取在测试集上表现最好的。
![TIM截图20180916145510](screenshots/TIM%E6%88%AA%E5%9B%BE20180916145510.png)
这看似合理。测试集的目的是观察我们的模型在没遇到的数据上算法表现如何。但仅仅选择在测试集上表现良好超参数并不足够，因为我们的测试数据集无法代表全新的未见数据。
3. 最好的方法是将数据集分成3部分。
![TIM截图20180916145752](screenshots/TIM%E6%88%AA%E5%9B%BE20180916145752.png)
大部分作为数据集，一部分作为验证集，一部分作为测试集。选择在验证集上表现最好的超参数组合，然后应用到测试集中去。模型在测试集上的表现才是要写进论文和报告里的内容。

如果数据集过小，可以使用交叉验证的方法。
![TIM截图20180916150057](screenshots/TIM%E6%88%AA%E5%9B%BE20180916150057.png)
例如，我们可以将测试数据分成5份，每轮训练采用不同的部分轮流当作验证集。

选取数据的过程中，尽量保证数据最大程度地反应现实世界。
![TIM截图20180916150433](screenshots/TIM%E6%88%AA%E5%9B%BE20180916150433.png)
我们可以通过绘图的方法将不同超参数组合下模型的表现可视化。我们可以由此看出算法表现与超参数的的关系。

K近邻算法在图片领域其实**从不使用**。
1. 预测速度太慢。
2. L1距离和L2距离并不能很好地表征图片之间的差异。
![TIM截图20180916150636](screenshots/TIM%E6%88%AA%E5%9B%BE20180916150636.png)
以上4个图片差别很大，后面3个图片与第1张图片的L2距离却是完全相同的。

3. 维度灾难。
![TIM截图20180916150857](screenshots/TIM%E6%88%AA%E5%9B%BE20180916150857.png)
K近邻算法本质是用数据划分样本空间，当样本空间的维度增大时，需要的数据集便成倍增加。这将导致很低的效率。


### Numpy&Pandas
From [莫烦python](https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/)

[笔记在Numpy&Pandas.ipynb里](./Numpy&Pandas.ipynb)

## 问题
1. 采用别人的开源项目训练自己的数据时，如果维度不同会导致问题吗？


