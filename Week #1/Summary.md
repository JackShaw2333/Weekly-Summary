# Week #1
## 简介
1. 吴恩达的课程：主要关于深度卷积神经网络的实例探究。
2. CS231N主要关于一些简单的算法及其具体代码实现细节。
3. Numpy&Pandas入门学习。
## [网易云课堂 吴恩达 卷积神经网络](https://mooc.study.163.com/learn/2001281004?tid=2001392030#/learn/content)
### 2.5 网络中的网络以及1x1卷积
![TIM截图20180914092814](screenshots/TIM%E6%88%AA%E5%9B%BE20180914092814.png)
1x1卷积也称为`Network in network`，因为每一次卷积相当于一个全连接层，对输入层的1x1x信道数切片进行运算。
它给神经网络添加了一个非线性函数，并能够在保持输入层长宽的基础上改变信道的数量。
输出结果的信道数等于使用的卷积核的数量。
1x1卷积在`Inception网络`中得到应用

### 2.6 谷歌Inception网络简介
Inception网络可以代替人工确定卷积层中的卷积核类型，确定是否需要创建卷积层或池化层。
![Inception网络](screenshots/TIM%E6%88%AA%E5%9B%BE20180914094011.png)
以上图为例，输入层为`28x28x192`。
1. 先使用64个1x1的卷积核，输出大小为28x28x64。
2. 再使用128个3x3的`Same`卷积核，输出大小为28x28x128，将这一层叠到上一个输出层上。
3. 然后使用32个5x5的`Same`卷积核，输出大小为28x28x32，将这一层叠到之前的输出层上。
4. 最后再进行最大值池化，`Same padding`，步长为1，输出大小为28x28x32，继续叠到之前的输出层上去。

这样就粗略得到了一个`Inception模块`，对于这个例子而言，输入为28x28x192，输出为28x28x256。
以上就是`Inception模块`的核心内容。
基本思想是：Inception网络不需要人为决定需要哪种卷积核或是否需要池化，而是由网络自行决定。我们可以对网络使用这些参数然后把输出连接起来。让网络自己学习它需要什么参数，采用哪些卷积核组合。


然而不难发现，Inception网络存在计算成本的问题。
以使用32个5x5的卷积核进行`Same`卷积，输入层为28x28x192为例。
32个5x5的卷积核，每个卷积核大小为5x5x192，而输出为28x28x32，即要计算28x28x32个数字，而对于其中的每个数字，都要进行5x5x192次运算。所以**乘法运算的总次数为每个输出值所需的乘法次数乘输出的值个数**，这里的结果大约为**1.2亿**次乘法运算。


然而，当我们应用`1x1卷积`后，计算量可降低为原先的十分之一。
![TIM截图20180914150926](screenshots/TIM%E6%88%AA%E5%9B%BE20180914150926.png)
然后对这个较小层，运用5x5的卷积核，同样输出层大小为28x28x32。
![TIM截图20180914151108](TIM%E6%88%AA%E5%9B%BE20180914151108.png)
通过这样1x1卷积构建`瓶颈层`可降低运算量，先缩小网络表示，再增大它们。
这样计算成本为：
1. 构建瓶颈层，计算量为28x28x16x192，约等于240万
2. 对于第二个卷积层，计算量为28x28x32x5x5x16，约等于1000万。

所以总乘法次数为1240万（加法次数与乘法次数近似相同）







### 2.7 Inception网络
Inception模块主要使用之前层的激活或输出作为输入。
还以28x28x192的输入层为例
![TIM截图20180914191812](screenshots/TIM%E6%88%AA%E5%9B%BE20180914151108.png)









1. 16个1x1卷积核卷积，32个5x5卷积核`Same`卷积，输出大小为28x28x32
2. 16个1x1卷积核卷积，128个3x3卷积核`Same`卷积，输出大小为28x28x128
3. 64个1x1卷积核卷积。
4. 3x3，步长1的最大值池化层`Same`池化，然后再用32个1x1的卷积核压缩信道数量。输出为28x28x32。
5. 最后将所有信道连接在一起。完成了一个Inception模块的构建。




















![TIM截图20180914192852](screenshots/TIM%E6%88%AA%E5%9B%BE20180914191812.png)
将许多重复的Inception模块连接在一起，就构建了一个Inception网络。有的模块与模块之间存在池化层条件维度大小。




















![TIM截图20180914194142](screenshots/TIM%E6%88%AA%E5%9B%BE20180914192852.png)
其中有一个细节要注意，Inception网络同时还有几条分支，这几条分支是用`Softmax`进行预测的全连接层。它们确保了即便是隐藏单元和中间层，也参与了特征计算，得出了对图片的分类。对整个Inception网络起到了调整的作用，也防止了网络发生过拟合。

论文：[[Szegedy et al.,2014, Going Deeper with Convolutions]](https://arxiv.org/abs/1409.4842)







### 2.8 使用开源的实现方案
搭建计算机视觉网络比较好的方式是使用自己感兴趣的框架，到Github上下载开源的实现。这样做可以节省许多从头开始训练网络的时间。我们就可以利用这些预训练的网络进行迁移学习，运用到我们的网络上去。






### 2.9 迁移学习
做计算机视觉项目时，可以下载开源项目，利用他人已经训练好的网络结构的权重，将之作为预训练，然后转换到自己感兴趣的任务上。

例如，我们要搭建一个识别猫的3分类神经网络。我们可以下载别人预训练好的网络模型。如我们下载了`ImageNet数据集`的网络，这个网络用Softmax输出1000种类别。我们可以删去它的Softmax层，用我们自己的3分类的Softmax层替代。
若训练数据少，可冻结之前的隐层，只训练最后的Softmax层的参数。这样，即便训练数据不大，我们仍能得到较好的效果。
许多框架都支持这种`冻结参数`的操作。

还有一个能加快计算速度的小技巧。由于前面的层都冻结了，相当于一个固定的函数。
![TIM截图20180914200147](screenshots/TIM%E6%88%AA%E5%9B%BE20180914194142.png)
然后我们将输入图片直接映射到Softmax层的前一层的激活函数中去。如果我们这样先计算这一层的特征或激活值，然后把它们存到硬盘，实际上就是用一个固定的函数，取任意图像，计算它的特征向量，这样就训练了一个很浅的Softmax模型，然后将参数权重存到硬盘。这样每次遍历就不需要再训练这一层的激活值了。

如果数据集较多，我们可以少冻结一些层。冻结前面的层，训练后面的层。









![TIM截图20180914200903](screenshots/TIM%E6%88%AA%E5%9B%BE20180914200147.png)
我们可以将后面几层原有的参数看作随机初始化然后进行梯度下降。
或者直接去掉后面几层换成自己隐藏单元。

有个规律：数据越多，需要冻结的层数就越少。
如果有大量数据，不要仅仅训练一个Softmax层，最好训练一个中等深度的网络。包含最终要用的网络的后面几层。
如果数据量足够大，可以完全自己训练。

### 2.10 数据扩充
计算机视觉的一个特点：数据越多结果可能越好。
计算机视觉的一个问题：数据不够

常见的数据扩充方法：
![TIM截图20180914203659](screenshots/TIM%E6%88%AA%E5%9B%BE20180914200903.png)
垂直镜像对称












![TIM截图20180914203837](screenshots/TIM%E6%88%AA%E5%9B%BE20180914203659.png)
随机修剪（不完美）






旋转、局部扭曲（不推荐）


![TIM截图20180914204330](screenshots/TIM%E6%88%AA%E5%9B%BE20180914203837.png)
色彩转换，修改RGB值（可使用PCA颜色增强算法）
PCA增强算法将会使图片的RGB值趋向平均。如图片呈现紫色，则主要含红色与蓝色，而绿色很少，PCA算法便会将红色与蓝色的值减少很多，适当增加绿色值以使总体的颜色保持一致。










如果数据过大，那么数据的扩充和训练过程可并行执行。
使用CPU线程不停地从硬盘读取图片流，同时实现对图片的扭曲（垂直反转/随机裁剪/色彩转换）。每一种照片得到对应的一种扭曲形式。与此同时CPU线程不断加载数据，然后实现任意扭曲，从而构成批数据或最小批数据。这些数据持续地传给其他线程或其他进程然后训练。这些可以在CPU或者GPU上运行。

常用的数据增强方法是使用一个线程或多线程，这些可以用来加载数据和实现扭曲操作，然后传给其他线程或进程，以上这些都可以并行实现。

与构建神经网络相同，数据增强也有许多超参数需要设置。推荐的方法是使用别人的开源实现。


### 2.11 计算机视觉现状







![TIM截图20180914205653](screenshots/TIM%E6%88%AA%E5%9B%BE20180914204330.png)
计算机视觉的数据相比其他领域偏少。
目标检测的数据相比物体识别更少。
当数据集很大时，人们倾向于使用简单的算法和更少的手工工程，因此人们不需要对这个问题精心设计。相反，我们可以用一个巨大的神经网络或一个简单的框架。
然而当没有那么多数据时，人们更多从事的是手工工程。当没有足够数据时，手工工程是获得良好表现的最佳方法。

算法一般有两种知识来源：
1. 被标记的数据。
2. 手工工程

人们精心建立一个系统，精心设计特性、网络特征结构或者是系统的其他组件。当没有太多的标记数据时，就需要更多的考虑手工工程。因此历史上，计算机视觉领域更加依赖手工工程。

在benchmarks训练出更好的结果就可以发表论文；对于计算机视觉比赛，模型表现提高1%、2%都很重要。针对这方面有一些技巧可以使用。

1. 集成。想好了自己的神经网络后，独立地再训练几个网络，然后将输出值平均。（不要平均它们的权重），这能够使表现提高1%、2%或更高。然而计算量成倍增加，因此不使用在为客户服务的系统上。
2. Multi-crop. 将数据增强应用到**测试集**中。如`10-crop`算法，![TIM截图20180914191812](screenshots/TIM%E6%88%AA%E5%9B%BE20180914205653.png)
![TIM截图20180914211245](screenshots/TIM%E6%88%AA%E5%9B%BE20180914211122.png)
![TIM截图20180914211411](TIM%E6%88%AA%E5%9B%BE20180914211411.png)右上，左下，右下四个角进行crop，就得到4张图片
![TIM截图20180914211245](screenshots/TIM%E6%88%AA%E5%9B%BE20180914211411.png)
![TIM截图20180914211506](screenshots/TIM%E6%88%AA%E5%9B%BE20180914211506.png)
一共剪切出10张图片。然后用分类器运行这10张图片再将输出平均。

总之以上的方法使得计算量增大，耗时增长。研究论文和比赛时可以使用这些技巧，但是在开发部署客户的系统上，不推荐使用这些方法。

下图是开发模型的一些建议
![TIM截图20180914211942](screenshots/TIM%E6%88%AA%E5%9B%BE20180914211942.png)






## 斯坦福CS231N课程

### 2.1 图像分类 - 数据驱动方法
 关于K近邻算法，要防止过拟合现象的产生，K需要适当取大于1的数。
 K近邻算法的缺点在于训练快而预测慢，与实际需求冲突

### 2.2 图像分类 - K最近邻算法
L1(Manhattan)距离
![$$d_1(I_1,I_2)=\sum_p|I_1^p-I_2^p|$$](http://latex.codecogs.com/gif.latex?\\$$d_1(I_1,I_2)=\sum_p|I_1^p-I_2^p|$$)​

L2(Euclidean)距离
![$$d_1(I_1,I_2)=\sqrt{\sum_p(I_1^p-I_2^p)^2}$$](http://latex.codecogs.com/gif.latex?\\$$d_1(I_1,I_2)=\sqrt{\sum_p(I_1^p-I_2^p)^2}$$)​

将数据分为`训练集`、`验证集`、`测试集`是较好的**寻找最佳超参数**的方法。
当数据较小时，可用**交叉验证**的方法，将数据集平分几份，每份轮流作验证集

K近邻算法的缺点：
1. 训练快，预测慢。
2. L1和L2距离算法不适合表示图像之间的相似度。
3. 需要训练点分布得尽可能密集，这样导致训练数据成倍增加，尤其在高维时所需的数据很大。

## Numpy&Pandas
From [莫烦python](https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/)

[笔记，戳这里](./Week1.ipynb)



