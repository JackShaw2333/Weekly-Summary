{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 了解网页结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了正常显示中文，`read()`之后要使用`decode()`使文字转换为成可以正常显示中文的形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"cn\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>Scraping tutorial 1 | 莫烦Python</title>\n",
      "\t<link rel=\"icon\" href=\"https://morvanzhou.github.io/static/img/description/tab_icon.png\">\n",
      "</head>\n",
      "<body>\n",
      "\t<h1>爬虫测试1</h1>\n",
      "\t<p>\n",
      "\t\t这是一个在 <a href=\"https://morvanzhou.github.io/\">莫烦Python</a>\n",
      "\t\t<a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n",
      "\t</p>\n",
      "\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "# if has Chinese, apply decode()\n",
    "html=urlopen(\n",
    "    \"https://morvanzhou.github.io/static/scraping/basic-structure.html\"\n",
    ").read().decode('utf-8')\n",
    "\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Page title is: Scraping tutorial 1 | 莫烦Python\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "res=re.findall(r'<title>(.+?)</title>',html)\n",
    "print('\\nPage title is: {}'.format(res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Page paragraph is: \n",
      "\t\t这是一个在 <a href=\"https://morvanzhou.github.io/\">莫烦Python</a>\n",
      "\t\t<a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "res=re.findall(r'<p>(.*?)</p>',html,flags=re.DOTALL)\n",
    "print('\\nPage paragraph is: {}'.format(res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nAll links: ['https://morvanzhou.github.io/static/img/description/tab_icon.png', 'https://morvanzhou.github.io/', 'https://morvanzhou.github.io/tutorials/data-manipulation/scraping/']\n"
     ]
    }
   ],
   "source": [
    "res=re.findall(r'href=\"(.*?)\"',html)\n",
    "print('nAll links: {}'.format(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## BeautifulSoup解析网页\n",
    "用于简化提取内容\n",
    "\n",
    "[中文官方文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"cn\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>Scraping tutorial 1 | 莫烦Python</title>\n",
      "\t<link rel=\"icon\" href=\"https://morvanzhou.github.io/static/img/description/tab_icon.png\">\n",
      "</head>\n",
      "<body>\n",
      "\t<h1>爬虫测试1</h1>\n",
      "\t<p>\n",
      "\t\t这是一个在 <a href=\"https://morvanzhou.github.io/\">莫烦Python</a>\n",
      "\t\t<a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n",
      "\t</p>\n",
      "\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "html = urlopen(\n",
    "    \"https://morvanzhou.github.io/static/scraping/basic-structure.html\"\n",
    ").read().decode('utf-8')\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>爬虫测试1</h1>\n",
      "\n",
      " <p>\n",
      "\t\t这是一个在 <a href=\"https://morvanzhou.github.io/\">莫烦Python</a>\n",
      "<a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n",
      "\t</p>\n"
     ]
    }
   ],
   "source": [
    "soup=BeautifulSoup(html,features='lxml')\n",
    "print(soup.h1)\n",
    "print('\\n',soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://morvanzhou.github.io/\">莫烦Python</a>, <a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">爬虫教程</a>]\n",
      "https://morvanzhou.github.io/\n",
      "https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\n"
     ]
    }
   ],
   "source": [
    "all_href=soup.find_all('a')\n",
    "print(all_href)\n",
    "#all_href=[l['href'] for l in all_href]\n",
    "#print('\\n',all_href)\n",
    "for l in all_href:\n",
    "    print(l['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html=urlopen(\n",
    "    \"https://morvanzhou.github.io/static/scraping/list.html\"\n",
    ").read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一月\n",
      "二月\n",
      "三月\n",
      "四月\n",
      "五月\n"
     ]
    }
   ],
   "source": [
    "soup=BeautifulSoup(html,features='lxml')\n",
    "\n",
    "month=soup.find_all('li',{\"class\":\"month\"}) \n",
    "#通过字典指定class\n",
    "for m in month:\n",
    "    print(m.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一月一号\n",
      "一月二号\n",
      "一月三号\n"
     ]
    }
   ],
   "source": [
    "jan=soup.find('ul',{\"class\":\"jan\"})\n",
    "d_jan=jan.find_all('li')\n",
    "for d in d_jan:\n",
    "    print(d.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "html=urlopen(\n",
    "    'https://morvanzhou.github.io/static/scraping/table.html'\n",
    ").read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://morvanzhou.github.io/static/img/course_cover/tf.jpg\n",
      "https://morvanzhou.github.io/static/img/course_cover/rl.jpg\n",
      "https://morvanzhou.github.io/static/img/course_cover/scraping.jpg\n"
     ]
    }
   ],
   "source": [
    "soup=BeautifulSoup(html,features='lxml')\n",
    "\n",
    "img_links=soup.find_all('img',{'src':re.compile('.*?\\.jpg')})\n",
    "for link in img_links:\n",
    "    print(link['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://morvanzhou.github.io/\n",
      "https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\n",
      "https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/\n",
      "https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/\n",
      "https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\n"
     ]
    }
   ],
   "source": [
    "course_links=soup.find_all('a',{'href':re.compile('https://morvan.*')})\n",
    "\n",
    "for link in course_links:\n",
    "    print(link['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 爬百度百科"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置起始页. 并将 `/item/...` 的网页都放在 `his` 中, 做一个备案, 记录我们浏览过的网页."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url='https://baike.baidu.com'\n",
    "his = ['/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/5162711']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "网络爬虫 url: /item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/5162711\n"
     ]
    }
   ],
   "source": [
    "url=base_url+his[-1]\n",
    "\n",
    "html=urlopen(url).read().decode('utf-8')\n",
    "soup=BeautifulSoup(html,features='lxml')\n",
    "print(soup.find('h1').get_text(),'url: {}'.format(his[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/5162711', '/item/%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F']\n"
     ]
    }
   ],
   "source": [
    "sub_urls=soup.find_all('a',\n",
    "                      {\n",
    "                          'target':'_blank',\n",
    "                          'href':re.compile('/item/(%.{2})+$')\n",
    "                      })\n",
    "#print(sub_urls)\n",
    "if len(sub_urls)!=0:\n",
    "    new=random.sample(sub_urls,1)[0]['href']\n",
    "    his.append(new)\n",
    "else:\n",
    "    his.pop()\n",
    "print(his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 第二次世界大战 url: /item/%E7%AC%AC%E4%BA%8C%E6%AC%A1%E4%B8%96%E7%95%8C%E5%A4%A7%E6%88%98\n",
      "2 捷克斯洛伐克 url: /item/%E6%8D%B7%E5%85%8B%E6%96%AF%E6%B4%9B%E4%BC%90%E5%85%8B\n",
      "3 古斯塔夫·胡萨克 url: /item/%E5%8F%A4%E6%96%AF%E5%A1%94%E5%A4%AB%C2%B7%E8%83%A1%E8%90%A8%E5%85%8B\n",
      "4 天鹅绒革命 url: /item/%E5%A4%A9%E9%B9%85%E7%BB%92%E9%9D%A9%E5%91%BD\n",
      "5 实验员 url: /item/%E5%AE%9E%E9%AA%8C%E5%91%98\n",
      "6 国家职业资格 url: /item/%E5%9B%BD%E5%AE%B6%E8%81%8C%E4%B8%9A%E8%B5%84%E6%A0%BC\n",
      "7 项目管理师 url: /item/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%B8%88\n",
      "8 工程勘察 url: /item/%E5%B7%A5%E7%A8%8B%E5%8B%98%E5%AF%9F\n",
      "9 遥感技术 url: /item/%E9%81%A5%E6%84%9F%E6%8A%80%E6%9C%AF\n",
      "10 海南岛 url: /item/%E6%B5%B7%E5%8D%97%E5%B2%9B\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    url=base_url+his[-1]\n",
    "    \n",
    "    html=urlopen(url).read().decode('utf-8')\n",
    "    soup=BeautifulSoup(html,features='lxml')\n",
    "    print(i+1,soup.find('h1').get_text(),'url: {}'.format(his[-1]))\n",
    "    \n",
    "    sub_urls=soup.find_all('a',\n",
    "                          {\n",
    "                              'target':'_blank',\n",
    "                              'href':re.compile('/item/(%.{2})+$')\n",
    "                          })\n",
    "    if len(sub_urls)!=0:\n",
    "        his.append(random.sample(sub_urls,1)[0]['href'])\n",
    "    else:\n",
    "        his.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单Python匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "pattern1='cat'\n",
    "pattern2='bird'\n",
    "string='dog runs to cat'\n",
    "print(pattern1 in string)\n",
    "print(pattern2 in string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则寻找配对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(12, 15), match='cat'>\n"
     ]
    }
   ],
   "source": [
    "pattern1='cat'\n",
    "pattern2='bird'\n",
    "string='dog runs to cat'\n",
    "print(re.search(pattern1,string))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 匹配多种可能 使用[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(4, 7), match='run'>\n",
      "<_sre.SRE_Match object; span=(4, 7), match='ran'>\n"
     ]
    }
   ],
   "source": [
    "ptn=r'r[au]n'\n",
    "#r[au]n表示ran, run皆可成功\n",
    "print(re.search(ptn,string))\n",
    "string='dog ran to cat'\n",
    "print(re.search(ptn,string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<_sre.SRE_Match object; span=(4, 7), match='run'>\n"
     ]
    }
   ],
   "source": [
    "print(re.search(r'r[A-Z]n','dog runs to cat'))\n",
    "print(re.search(r'r[0-9a-z]n','dog runs to cat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特殊种类匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(4, 7), match='r4n'>\n",
      "<_sre.SRE_Match object; span=(0, 3), match='run'>\n"
     ]
    }
   ],
   "source": [
    "# \\d :数字\n",
    "print(re.search(r'r\\dn','run r4n'))\n",
    "# \\D :不是数字的形式\n",
    "print(re.search(r'r\\Dn','run r4n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空白"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 3), match='r\\nn'>\n",
      "<_sre.SRE_Match object; span=(4, 7), match='r4n'>\n"
     ]
    }
   ],
   "source": [
    "# \\s :空白符\n",
    "# \\S :非空白符\n",
    "print(re.search(r'r\\sn','r\\nn r4n'))\n",
    "print(re.search(r'r\\Sn','r\\nn r4n'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 所有字母数字和“_”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(4, 7), match='r4n'>\n"
     ]
    }
   ],
   "source": [
    "# \\w :[a-zA-z0-9_]\n",
    "print(re.search(r'r\\wn','r\\nn r4n'))\n",
    "# \\W :相反"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空白字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(4, 8), match='runs'>\n",
      "None\n",
      "None\n",
      "<_sre.SRE_Match object; span=(4, 10), match=' runs '>\n"
     ]
    }
   ],
   "source": [
    "# \\b :词首和词尾的空白符\n",
    "# \\B :不是位于词首和词尾的空白符\n",
    "print(re.search(r'\\bruns\\b','dog runs to cat'))\n",
    "print(re.search(r'\\b runs \\b','dog  runs  to cat'))\n",
    "print(re.search(r'\\Bruns\\B','dog  runs  to cat'))\n",
    "print(re.search(r'\\B runs \\B','dog  runs  to cat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特殊字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 3), match='r-n'>\n"
     ]
    }
   ],
   "source": [
    "# \\\\ :匹配\\\n",
    "# . :匹配\\n以外所有字符\n",
    "print(re.search(r'r.n','r-ns to'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 句首句尾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 3), match='dog'>\n",
      "<_sre.SRE_Match object; span=(12, 15), match='cat'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ^ : 匹配句首\n",
    "# $ : 匹配句尾\n",
    "print(re.search(r'^dog','dog runs to cat'))\n",
    "print(re.search(r'cat$','dog runs to cat'))\n",
    "print(re.search(r'cat$','cat runs to dog'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 是否出现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 6), match='Monday'>\n",
      "<_sre.SRE_Match object; span=(0, 3), match='Mon'>\n"
     ]
    }
   ],
   "source": [
    "# ()? : ()里是否出现，出不出现都匹配\n",
    "print(re.search(r'Mon(day)?','Monday'))\n",
    "print(re.search(r'Mon(day)?','Mon'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多行匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<_sre.SRE_Match object; span=(18, 19), match='I'>\n"
     ]
    }
   ],
   "source": [
    "string = '''\n",
    "dog runs to cat.\n",
    "I run to dog.\n",
    "'''\n",
    "print(re.search(r'^I',string))\n",
    "print(re.search(r'^I',string,flags=re.M))\n",
    "# flags=re.M使string中每一个换行后的句子都被当成一行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0或多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 1), match='a'>\n",
      "<_sre.SRE_Match object; span=(0, 2), match='ab'>\n",
      "<_sre.SRE_Match object; span=(0, 6), match='abbbbb'>\n"
     ]
    }
   ],
   "source": [
    "# * \n",
    "print(re.search(r'ab*','a'))\n",
    "print(re.search(r'ab*','ab'))\n",
    "print(re.search(r'ab*','abbbbb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1或多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<_sre.SRE_Match object; span=(0, 2), match='ab'>\n",
      "<_sre.SRE_Match object; span=(0, 6), match='abbbbb'>\n"
     ]
    }
   ],
   "source": [
    "# +\n",
    "print(re.search(r'ab+','a'))\n",
    "print(re.search(r'ab+','ab'))\n",
    "print(re.search(r'ab+','abbbbb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可选次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "<_sre.SRE_Match object; span=(0, 5), match='abbbb'>\n"
     ]
    }
   ],
   "source": [
    "# {n, m} : 出现n到m次\n",
    "print(re.search(r'ab{2,10}','a'))\n",
    "print(re.search(r'ab{2,10}','ab'))\n",
    "print(re.search(r'ab{2,10}','abbbb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "021523, Date: Feb/12/2017\n",
      "021523\n"
     ]
    }
   ],
   "source": [
    "# () group的信息\n",
    "match=re.search(r'(\\d+), Date: (.+)','ID: 021523, Date: Feb/12/2017')\n",
    "print(match.group())\n",
    "print(match.group(1)) #只返回第1个括号匹配的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "021523\n"
     ]
    }
   ],
   "source": [
    "# ?P<group名> : 给group命名\n",
    "match=re.search(r'(?P<id>\\d+), Date: (?P<date>.+)','ID: 021523, Date: Feb/12/2017')\n",
    "print(match.group('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找所有匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'ran']\n",
      "['run', 'ran']\n"
     ]
    }
   ],
   "source": [
    "# findall\n",
    "print(re.findall(r'r[ua]n','run ran ren'))\n",
    "print(re.findall(r'(ran|run)','run ran ren'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog catches to cats\n"
     ]
    }
   ],
   "source": [
    "# re.sub()\n",
    "print(re.sub(r'r[au]ns','catches','dog runs to cats'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分裂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e']\n"
     ]
    }
   ],
   "source": [
    "# re.split()\n",
    "print(re.split(r'[;,\\.]','a;b,c.d;e'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(4, 7), match='ran'>\n"
     ]
    }
   ],
   "source": [
    "compiled_re=re.compile(r'r[au]n')\n",
    "print(compiled_re.search('dog ran to cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
